{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AML Project 5 - Federated Learning - Track B\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# %!pip install torch torchvision tqdm tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import dataclasses\n",
    "import logging\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Literal, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
    "from torchvision.datasets.cifar import CIFAR100\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TqdmLoggingHandler(logging.Handler):\n",
    "    def emit(self, record):\n",
    "        try:\n",
    "            msg = self.format(record)\n",
    "            tqdm.write(\"\\r\\033[K\" + msg)\n",
    "            self.flush()\n",
    "        except Exception:\n",
    "            self.handleError(record)\n",
    "\n",
    "\n",
    "class ColoredFormatter(logging.Formatter):\n",
    "    COLORS = {\n",
    "        \"DEBUG\": \"\\033[1;34m\",\n",
    "        \"INFO\": \"\\033[1;32m\",\n",
    "        \"WARNING\": \"\\033[1;33m\",\n",
    "        \"ERROR\": \"\\033[1;31m\",\n",
    "        \"CRITICAL\": \"\\033[1;35m\",\n",
    "        \"RESET\": \"\\033[0m\",\n",
    "    }\n",
    "\n",
    "    def format(self, record):\n",
    "        levelname = record.levelname\n",
    "        if levelname in self.COLORS:\n",
    "            record.levelname = (\n",
    "                f\"{self.COLORS[levelname]}{levelname}{self.COLORS['RESET']}\"\n",
    "            )\n",
    "        return super().format(record)\n",
    "\n",
    "\n",
    "def setup_logging(level=logging.INFO):\n",
    "    root_logger = logging.getLogger()\n",
    "    root_logger.handlers.clear()\n",
    "    root_logger.setLevel(level)\n",
    "\n",
    "    tqdm_handler = TqdmLoggingHandler()\n",
    "    formatter = ColoredFormatter(\n",
    "        fmt=\"%(asctime)s [%(levelname)s] %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "    )\n",
    "    tqdm_handler.setFormatter(formatter)\n",
    "    root_logger.addHandler(tqdm_handler)\n",
    "\n",
    "\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class BaseConfig:\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    CPU_COUNT = os.cpu_count() or 1\n",
    "    NUM_WORKERS = min(4, CPU_COUNT)\n",
    "    SEED = 42\n",
    "\n",
    "    # Paths\n",
    "    ROOT_DIR: Path = Path.cwd()\n",
    "    CONFIGS_DIR: Path = ROOT_DIR / \"configs\"\n",
    "    DATA_DIR: Path = ROOT_DIR / \"data\"\n",
    "    MODELS_DIR: Path = ROOT_DIR / \"models\"\n",
    "    RESULTS_DIR: Path = ROOT_DIR / \"results\"\n",
    "    RUNS_DIR: Path = ROOT_DIR / \"runs\"\n",
    "    OLD_RUNS_DIR: Path = RUNS_DIR / \"old_runs\"\n",
    "\n",
    "    # Training Parameters\n",
    "    BATCH_SIZE = 64\n",
    "    LEARNING_RATE = 0.01\n",
    "    NUM_EPOCHS = 20\n",
    "    MOMENTUM = 0.9\n",
    "    WEIGHT_DECAY = 4e-4\n",
    "    NUM_CLASSES = 100\n",
    "\n",
    "\n",
    "# Create directories\n",
    "config = BaseConfig()\n",
    "for dir_path in [\n",
    "    config.DATA_DIR,\n",
    "    config.MODELS_DIR,\n",
    "    config.RESULTS_DIR,\n",
    "    config.CONFIGS_DIR,\n",
    "    config.RUNS_DIR,\n",
    "    config.OLD_RUNS_DIR,\n",
    "]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class FederatedConfig(BaseConfig):\n",
    "    \"\"\"Federated Learning specific configuration.\"\"\"\n",
    "\n",
    "    NUM_CLIENTS: int = 100\n",
    "    PARTICIPATION_RATE: float = 0.1\n",
    "    LOCAL_EPOCHS: int = 4\n",
    "    NUM_ROUNDS: int = 10\n",
    "    CLASSES_PER_CLIENT: Optional[int] = None  # None for IID\n",
    "    PARTICIPATION_MODE: str = \"uniform\"\n",
    "    DIRICHLET_ALPHA: Optional[float] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        self.connected = nn.Sequential(\n",
    "            nn.Linear(5 * 5 * 64, 384),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(384, 192),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(192, config.NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.connected(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsManager:\n",
    "    \"\"\"Manages logging and visualization of training metrics.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: BaseConfig,\n",
    "        model_name: str,\n",
    "        training_type: Literal[\"centralized\", \"federated\"],\n",
    "        experiment_name: Optional[str] = None,\n",
    "    ):\n",
    "        self.config = config\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "        # Archive old runs\n",
    "        old_runs = list(config.RUNS_DIR.glob(f\"{training_type}_{model_name}_*\"))\n",
    "        if old_runs:\n",
    "            archive_dir = config.OLD_RUNS_DIR\n",
    "            archive_dir.mkdir(exist_ok=True)\n",
    "            for run in old_runs:\n",
    "                run.rename(archive_dir / run.name)\n",
    "\n",
    "        # Create descriptive run name for FL experiments\n",
    "        if experiment_name:\n",
    "            experiment_suffix = f\"{experiment_name}_{timestamp}\"\n",
    "        elif training_type == \"federated\" and isinstance(config, FederatedConfig):\n",
    "            distribution = (\n",
    "                \"iid\"\n",
    "                if config.CLASSES_PER_CLIENT is None\n",
    "                else f\"noniid_{config.CLASSES_PER_CLIENT}cls\"\n",
    "            )\n",
    "            participation = f\"{config.PARTICIPATION_MODE}\"\n",
    "            if config.PARTICIPATION_MODE == \"skewed\":\n",
    "                participation += f\"_alpha{config.DIRICHLET_ALPHA}\"\n",
    "            clients_info = f\"C{config.NUM_CLIENTS}_P{config.PARTICIPATION_RATE}_E{config.LOCAL_EPOCHS}\"\n",
    "            experiment_suffix = (\n",
    "                f\"{distribution}_{participation}_{clients_info}_{timestamp}\"\n",
    "            )\n",
    "        else:\n",
    "            experiment_suffix = timestamp\n",
    "\n",
    "        run_name = f\"{training_type}_{model_name}_{experiment_suffix}\"\n",
    "        self.writer = SummaryWriter(config.RUNS_DIR / run_name)\n",
    "\n",
    "    def log_metrics(\n",
    "        self,\n",
    "        split: Literal[\"train\", \"validation\", \"test\"],\n",
    "        loss: float,\n",
    "        accuracy: float,\n",
    "        step: int,\n",
    "    ) -> None:\n",
    "        \"\"\"Log metrics for specified split.\"\"\"\n",
    "        self.writer.add_scalars(\"metrics/loss\", {split: loss}, step)\n",
    "        self.writer.add_scalars(\"metrics/accuracy\", {split: accuracy}, step)\n",
    "\n",
    "    def log_fl_metrics(\n",
    "        self, round_idx: int, metrics: Dict, client_stats: Optional[Dict] = None\n",
    "    ) -> None:\n",
    "        \"\"\"Log federated learning specific metrics.\"\"\"\n",
    "        # Log test metrics\n",
    "        self.log_metrics(\n",
    "            \"test\", metrics[\"test_loss\"], metrics[\"test_accuracy\"], round_idx\n",
    "        )\n",
    "\n",
    "        # Log client participation if available\n",
    "        if client_stats:\n",
    "            self.writer.add_scalars(\"federated/client_stats\", client_stats, round_idx)\n",
    "\n",
    "    def close(self) -> None:\n",
    "        \"\"\"Close TensorBoard writer.\"\"\"\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar100DatasetManager:\n",
    "    config: BaseConfig\n",
    "    validation_split: float\n",
    "    train_transform: transforms.Compose\n",
    "    test_transform: transforms.Compose\n",
    "    train_loader: DataLoader[CIFAR100]\n",
    "    val_loader: DataLoader[CIFAR100]\n",
    "    test_loader: DataLoader[CIFAR100]\n",
    "\n",
    "    def __init__(self, config: BaseConfig, validation_split: float = 0.1) -> None:\n",
    "        self.config = config\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "        self.train_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomCrop(32, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    [0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.test_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    [0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.train_loader, self.val_loader, self.test_loader = self._prepare_data()\n",
    "\n",
    "    def _prepare_data(\n",
    "        self,\n",
    "    ) -> Tuple[DataLoader[CIFAR100], DataLoader[CIFAR100], DataLoader[CIFAR100]]:\n",
    "        full_trainset: CIFAR100 = CIFAR100(\n",
    "            root=self.config.DATA_DIR,\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=self.train_transform,\n",
    "        )\n",
    "\n",
    "        train_size: int = int((1 - self.validation_split) * len(full_trainset))\n",
    "        val_size: int = len(full_trainset) - train_size\n",
    "\n",
    "        train_dataset, val_dataset = random_split(\n",
    "            full_trainset,\n",
    "            [train_size, val_size],\n",
    "            generator=torch.Generator().manual_seed(self.config.SEED),\n",
    "        )\n",
    "\n",
    "        test_dataset: CIFAR100 = CIFAR100(\n",
    "            root=self.config.DATA_DIR,\n",
    "            train=False,\n",
    "            download=False,\n",
    "            transform=self.test_transform,\n",
    "        )\n",
    "\n",
    "        loader_kwargs = {\"num_workers\": self.config.NUM_WORKERS, \"pin_memory\": True}\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config.BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            **loader_kwargs,\n",
    "        )\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=self.config.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            **loader_kwargs,\n",
    "        )\n",
    "\n",
    "        test_loader: DataLoader[CIFAR100] = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.config.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            **loader_kwargs,\n",
    "        )\n",
    "\n",
    "        return train_loader, val_loader, test_loader\n",
    "\n",
    "    @property\n",
    "    def train_dataset(self) -> Dataset[CIFAR100]:\n",
    "        return self.train_loader.dataset\n",
    "\n",
    "    @property\n",
    "    def val_dataset(self) -> Dataset[CIFAR100]:\n",
    "        return self.val_loader.dataset\n",
    "\n",
    "    @property\n",
    "    def test_dataset(self) -> Dataset[CIFAR100]:\n",
    "        return self.test_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentralizedTrainer:\n",
    "    model: LeNet\n",
    "    config: BaseConfig\n",
    "    device: torch.device\n",
    "    metrics: MetricsManager\n",
    "\n",
    "    def __init__(self, model: LeNet, config: BaseConfig) -> None:\n",
    "        self.model = model.to(config.DEVICE)\n",
    "        self.config = config\n",
    "        self.device = config.DEVICE\n",
    "        self.metrics = MetricsManager(\n",
    "            config, model.__class__.__name__.lower(), \"centralized\"\n",
    "        )\n",
    "\n",
    "    def evaluate_model(\n",
    "        self, model: LeNet, data_loader: DataLoader[CIFAR100]\n",
    "    ) -> Tuple[float, float]:\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in data_loader:\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        avg_loss: float = total_loss / total\n",
    "        accuracy: float = 100.0 * correct / total\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        train_loader: DataLoader[CIFAR100],\n",
    "        val_loader: DataLoader[CIFAR100],\n",
    "        test_loader: DataLoader[CIFAR100],\n",
    "        max_epochs: Optional[int] = None,\n",
    "    ) -> None:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=self.config.LEARNING_RATE,\n",
    "            momentum=self.config.MOMENTUM,\n",
    "            weight_decay=self.config.WEIGHT_DECAY,\n",
    "        )\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer=optimizer, T_max=self.config.NUM_EPOCHS\n",
    "        )\n",
    "\n",
    "        if max_epochs is None:\n",
    "            max_epochs = self.config.NUM_EPOCHS\n",
    "\n",
    "        best_val_loss = float(\"inf\")\n",
    "        best_model_state = None\n",
    "        patience = 10\n",
    "        patience_counter = 0\n",
    "        train_acc = 0.0\n",
    "        avg_train_loss = 0.0\n",
    "        device_type = str(self.device)\n",
    "\n",
    "        epoch_pbar = tqdm(\n",
    "            range(max_epochs or self.config.NUM_EPOCHS),\n",
    "            desc=\"Training\",\n",
    "            unit=\"epoch\",\n",
    "            position=0,\n",
    "            leave=True,\n",
    "        )\n",
    "        epoch = 0\n",
    "\n",
    "        try:\n",
    "            for epoch in epoch_pbar:\n",
    "                self.model.train()\n",
    "                train_loss = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "\n",
    "                # batch_pbar = tqdm(\n",
    "                #     train_loader,\n",
    "                #     desc=f\"Epoch {epoch}\",\n",
    "                #     colour=\"yellow\",\n",
    "                #     unit=\"batch\",\n",
    "                #     leave=True,\n",
    "                #     position=1,\n",
    "                #     bar_format='{l_bar}{bar:20}{r_bar}{bar:-10b}'\n",
    "                # )\n",
    "                for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "                    inputs = inputs.to(self.device, non_blocking=True)\n",
    "                    targets = targets.to(self.device, non_blocking=True)\n",
    "\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "                    with torch.amp.autocast_mode.autocast(device_type=device_type):\n",
    "                        outputs = self.model(inputs)\n",
    "                        loss = criterion(outputs, targets)\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item()\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    total += targets.size(0)\n",
    "                    correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                    # Update metrics\n",
    "                    train_acc = 100.0 * correct / total\n",
    "                    avg_train_loss = train_loss / (batch_idx + 1)\n",
    "\n",
    "                    global_step = epoch * len(train_loader) + batch_idx\n",
    "                    self.metrics.log_metrics(\n",
    "                        \"train\", avg_train_loss, train_acc, global_step\n",
    "                    )\n",
    "\n",
    "                    del inputs, targets, outputs, loss\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "                    # batch_pbar.set_postfix(\n",
    "                    #     {\"loss\": f\"{avg_train_loss:.3f}\", \"acc\": f\"{train_acc:.2f}%\"}\n",
    "                    # )\n",
    "\n",
    "                # Validation phase\n",
    "                val_loss, val_acc = self.evaluate_model(self.model, val_loader)\n",
    "                scheduler.step()\n",
    "\n",
    "                self.metrics.log_metrics(\"validation\", val_loss, val_acc, epoch)\n",
    "                epoch_pbar.set_postfix(\n",
    "                    {\n",
    "                        \"ep\": f\"{epoch+1}/{max_epochs or self.config.NUM_EPOCHS}\",\n",
    "                        \"tr_loss\": f\"{avg_train_loss:.3f}\",\n",
    "                        \"tr_acc\": f\"{train_acc:.1f}%\",\n",
    "                        \"val_loss\": f\"{val_loss:.3f}\",\n",
    "                        \"val_acc\": f\"{val_acc:.1f}%\",\n",
    "                    },\n",
    "                    refresh=True,\n",
    "                )\n",
    "\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_model_state = self.model.state_dict().copy()\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                if patience_counter >= patience:\n",
    "                    logging.info(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                logging.info(\"Training completed!\")\n",
    "            # Final evaluation\n",
    "            if best_model_state is not None:\n",
    "                self.model.load_state_dict(best_model_state)\n",
    "\n",
    "            test_loss, test_acc = self.evaluate_model(self.model, test_loader)\n",
    "            self.metrics.log_metrics(\"test\", test_loss, test_acc, epoch)\n",
    "            logging.info(\n",
    "                f\"Final Test Results - Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\"\n",
    "            )\n",
    "\n",
    "        finally:\n",
    "            self.metrics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientManager:\n",
    "    \"\"\"Manages clients data distribution and selection for federated learning.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: Dataset[CIFAR100],\n",
    "        num_clients: int,\n",
    "        participation_rate: float,\n",
    "        is_iid: bool = True,\n",
    "        participation_mode: str = \"uniform\",\n",
    "        dirichlet_alpha: Optional[float] = None,\n",
    "    ) -> None:\n",
    "        self.num_clients = num_clients\n",
    "        self.num_selected = int(participation_rate * num_clients)\n",
    "\n",
    "        # Create shards based on strategy\n",
    "        self.client_shards = (\n",
    "            self._create_iid_shards(dataset)\n",
    "            if is_iid\n",
    "            else self._create_noniid_shards(dataset)\n",
    "        )\n",
    "\n",
    "        # Setup selection probabilities\n",
    "        if participation_mode == \"skewed\":\n",
    "            if dirichlet_alpha is None:\n",
    "                raise ValueError(\"dirichlet_alpha required for skewed mode\")\n",
    "            self.selection_probs = np.random.dirichlet([dirichlet_alpha] * num_clients)\n",
    "        else:\n",
    "            self.selection_probs = np.ones(num_clients) / num_clients\n",
    "\n",
    "    def _create_iid_shards(self, dataset: Dataset[CIFAR100]) -> List[Subset[CIFAR100]]:\n",
    "        \"\"\"Create IID data shards.\"\"\"\n",
    "        if len(dataset) == 0:\n",
    "            raise ValueError(\"Empty dataset\")\n",
    "\n",
    "        indices = np.random.permutation(len(dataset))\n",
    "        shard_size = len(dataset) // self.num_clients\n",
    "\n",
    "        return [\n",
    "            Subset(dataset, indices[i : i + shard_size])\n",
    "            for i in range(0, len(indices), shard_size)\n",
    "        ]\n",
    "\n",
    "    def _create_noniid_shards(\n",
    "        self, dataset: Dataset[CIFAR100]\n",
    "    ) -> List[Subset[CIFAR100]]:\n",
    "        \"\"\"Create non-IID data shards using class distribution.\"\"\"\n",
    "        if not hasattr(dataset, \"targets\"):\n",
    "            raise ValueError(\n",
    "                \"Dataset must have 'targets' attribute for non-IID sharding\"\n",
    "            )\n",
    "\n",
    "        targets = np.array(dataset.targets)\n",
    "        class_indices = {\n",
    "            label: np.where(targets == label)[0]\n",
    "            for label in range(len(dataset.classes))\n",
    "        }\n",
    "\n",
    "        client_indices = []\n",
    "        for i in range(self.num_clients):\n",
    "            indices = []\n",
    "            # Select random classes for this client\n",
    "            selected_classes = np.random.choice(\n",
    "                list(class_indices.keys()),\n",
    "                size=min(5, len(class_indices)),  # Default to 5 classes per client\n",
    "                replace=False,\n",
    "            )\n",
    "\n",
    "            # Add samples from each selected class\n",
    "            for class_label in selected_classes:\n",
    "                class_samples = np.random.choice(\n",
    "                    class_indices[class_label],\n",
    "                    size=len(class_indices[class_label]) // self.num_clients,\n",
    "                    replace=False,\n",
    "                )\n",
    "                indices.extend(class_samples)\n",
    "\n",
    "            client_indices.append(Subset(dataset, indices))\n",
    "\n",
    "        return client_indices\n",
    "\n",
    "    def select_clients(self) -> List[int]:\n",
    "        \"\"\"Select clients for current round based on participation mode.\"\"\"\n",
    "        return np.random.choice(\n",
    "            self.num_clients,\n",
    "            size=self.num_selected,\n",
    "            replace=False,\n",
    "            p=self.selection_probs,\n",
    "        ).tolist()\n",
    "\n",
    "    def get_client_loader(\n",
    "        self,\n",
    "        client_idx: int,\n",
    "        batch_size: int,\n",
    "        num_workers: int = 4,\n",
    "        pin_memory: bool = True,\n",
    "    ) -> DataLoader:\n",
    "        \"\"\"Get DataLoader for a specific client.\"\"\"\n",
    "        return DataLoader(\n",
    "            self.client_shards[client_idx],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=pin_memory,\n",
    "            prefetch_factor=2,\n",
    "            persistent_workers=True,\n",
    "        )\n",
    "\n",
    "\n",
    "class FederatedClient:\n",
    "    config: FederatedConfig\n",
    "    model: LeNet\n",
    "    client_id: int\n",
    "    train_loader: DataLoader[CIFAR100]\n",
    "    local_epochs: int\n",
    "    device: torch.device\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        client_id: int,\n",
    "        model: LeNet,\n",
    "        train_loader: DataLoader[CIFAR100],\n",
    "        config: FederatedConfig,\n",
    "        local_epochs: int,\n",
    "    ) -> None:\n",
    "        self.config = config\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.client_id = client_id\n",
    "        self.train_loader = train_loader\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = config.DEVICE\n",
    "        self.device_type = str(config.DEVICE)\n",
    "\n",
    "    # TODO: call the centralized trainer?\n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=self.config.LEARNING_RATE,\n",
    "            momentum=self.config.MOMENTUM,\n",
    "            weight_decay=self.config.WEIGHT_DECAY,\n",
    "        )\n",
    "\n",
    "        for epoch in range(self.config.LOCAL_EPOCHS):\n",
    "            for inputs, targets in self.train_loader:\n",
    "                inputs = inputs.to(self.device, non_blocking=True)\n",
    "                targets = targets.to(self.device, non_blocking=True)\n",
    "\n",
    "                # optimizer.zero_grad()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                with torch.amp.autocast_mode.autocast(device_type=self.device_type):\n",
    "                    outputs = self.model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                del inputs, targets, outputs, loss\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "        return self.model\n",
    "\n",
    "\n",
    "# FIXME: use the validation set for evaluate clients between generations\n",
    "# and the test set for final evaluation\n",
    "class FederatedServer:\n",
    "    global_model: LeNet\n",
    "    client_manager: ClientManager\n",
    "    test_loader: DataLoader[CIFAR100]\n",
    "    config: FederatedConfig\n",
    "    device: torch.device\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: LeNet,\n",
    "        client_manager: ClientManager,\n",
    "        test_loader: DataLoader[CIFAR100],\n",
    "        config: FederatedConfig,\n",
    "    ) -> None:\n",
    "        self.global_model = model\n",
    "        self.client_manager = client_manager\n",
    "        self.test_loader = test_loader\n",
    "        self.config = config\n",
    "        self.device = config.DEVICE\n",
    "\n",
    "    def aggregate_models(self, client_models):\n",
    "        global_dict = self.global_model.state_dict()\n",
    "\n",
    "        for k in global_dict.keys():\n",
    "            global_dict[k] = torch.stack(\n",
    "                [\n",
    "                    client_model.state_dict()[k].float()\n",
    "                    for client_model in client_models\n",
    "                ],\n",
    "                0,\n",
    "            ).mean(0)\n",
    "\n",
    "        self.global_model.load_state_dict(global_dict)\n",
    "\n",
    "    def evaluate(self):\n",
    "        return CentralizedTrainer(self.global_model, self.config).evaluate_model(\n",
    "            self.global_model, self.test_loader\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FederatedManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: LeNet,\n",
    "        train_dataset: Dataset[CIFAR100],\n",
    "        test_loader: DataLoader[CIFAR100],\n",
    "        config: FederatedConfig,\n",
    "        experiment_name: Optional[str] = None,\n",
    "    ) -> None:\n",
    "        self.config = config\n",
    "        self.model = model.to(config.DEVICE)\n",
    "        self.device = config.DEVICE\n",
    "\n",
    "        # Initialize client manager with all client management functionality\n",
    "        self.client_manager = ClientManager(\n",
    "            dataset=train_dataset,\n",
    "            num_clients=config.NUM_CLIENTS,\n",
    "            participation_rate=config.PARTICIPATION_RATE,\n",
    "            is_iid=config.CLASSES_PER_CLIENT is None,\n",
    "            participation_mode=config.PARTICIPATION_MODE,\n",
    "            dirichlet_alpha=config.DIRICHLET_ALPHA,\n",
    "        )\n",
    "\n",
    "        self.server = FederatedServer(model, self.client_manager, test_loader, config)\n",
    "        self.metrics = MetricsManager(\n",
    "            config, model.__class__.__name__.lower(), \"federated\", experiment_name\n",
    "        )\n",
    "\n",
    "    def train(self) -> None:\n",
    "        round_pbar = tqdm(\n",
    "            range(self.config.NUM_ROUNDS),\n",
    "            desc=\"Training\",\n",
    "            unit=\"round\",\n",
    "            position=0,\n",
    "            colour=\"green\",\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            for round_idx in round_pbar:\n",
    "                selected_clients = self.client_manager.select_clients()\n",
    "                client_models = []\n",
    "\n",
    "                client_pbar = tqdm(\n",
    "                    selected_clients,\n",
    "                    desc=\"Clients\",\n",
    "                    unit=\"client\",\n",
    "                    position=1,\n",
    "                    colour=\"yellow\",\n",
    "                    leave=False,\n",
    "                )\n",
    "\n",
    "                for client_idx in client_pbar:\n",
    "                    client_loader = self.client_manager.get_client_loader(\n",
    "                        client_idx,\n",
    "                        self.config.BATCH_SIZE,\n",
    "                        num_workers=self.config.NUM_WORKERS,\n",
    "                    )\n",
    "\n",
    "                    client = FederatedClient(\n",
    "                        client_idx,\n",
    "                        self.server.global_model,\n",
    "                        client_loader,\n",
    "                        self.config,\n",
    "                        self.config.LOCAL_EPOCHS,\n",
    "                    )\n",
    "                    client_models.append(client.train())\n",
    "\n",
    "                self.server.aggregate_models(client_models)\n",
    "\n",
    "                # Evaluate and log\n",
    "                test_loss, accuracy = self.server.evaluate()\n",
    "                self.metrics.log_fl_metrics(\n",
    "                    round_idx,\n",
    "                    {\n",
    "                        \"test_loss\": test_loss,\n",
    "                        \"test_accuracy\": accuracy,\n",
    "                    },\n",
    "                    {\n",
    "                        \"num_selected\": len(selected_clients),\n",
    "                        \"participation_rate\": len(selected_clients)\n",
    "                        / self.config.NUM_CLIENTS,\n",
    "                    },\n",
    "                )\n",
    "\n",
    "                round_pbar.set_postfix(\n",
    "                    {\n",
    "                        \"test_loss\": f\"{test_loss:.4f}\",\n",
    "                        \"test_acc\": f\"{accuracy:.2f}%\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        finally:\n",
    "            self.metrics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data = Cifar100DatasetManager(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [10:30<00:00, 31.54s/epoch, ep=20/20, tr_loss=1.601, tr_acc=55.6%, val_loss=2.073, val_acc=46.0%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K2025-01-16 14:50:05 [\u001b[1;32mINFO\u001b[0m] Training completed!\n",
      "\u001b[K2025-01-16 14:50:17 [\u001b[1;32mINFO\u001b[0m] Final Test Results - Test Loss: 1.9331, Test Accuracy: 49.29%\n"
     ]
    }
   ],
   "source": [
    "model = LeNet(config)\n",
    "trainer = CentralizedTrainer(model, config)\n",
    "trainer.train(data.train_loader, data.val_loader, data.test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_config = FederatedConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|\u001b[32m██        \u001b[0m| 2/10 [06:25<25:41, 192.74s/round, test_loss=4.5905, test_acc=1.95%]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m fed_model \u001b[38;5;241m=\u001b[39m LeNet(config)\n\u001b[0;32m      2\u001b[0m fed_trainer \u001b[38;5;241m=\u001b[39m FederatedManager(\n\u001b[0;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mfed_model,\n\u001b[0;32m      4\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mtrain_dataset,\n\u001b[0;32m      5\u001b[0m     test_loader\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mtest_loader,\n\u001b[0;32m      6\u001b[0m     config\u001b[38;5;241m=\u001b[39mfed_config,\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m \u001b[43mfed_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[56], line 66\u001b[0m, in \u001b[0;36mFederatedManager.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m     client_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_manager\u001b[38;5;241m.\u001b[39mget_client_loader(\n\u001b[0;32m     54\u001b[0m         client_idx,\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mBATCH_SIZE,\n\u001b[0;32m     56\u001b[0m         num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mNUM_WORKERS,\n\u001b[0;32m     57\u001b[0m     )\n\u001b[0;32m     59\u001b[0m     client \u001b[38;5;241m=\u001b[39m FederatedClient(\n\u001b[0;32m     60\u001b[0m         client_idx,\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver\u001b[38;5;241m.\u001b[39mglobal_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mLOCAL_EPOCHS,\n\u001b[0;32m     65\u001b[0m     )\n\u001b[1;32m---> 66\u001b[0m     client_models\u001b[38;5;241m.\u001b[39mappend(\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver\u001b[38;5;241m.\u001b[39maggregate_models(client_models)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Evaluate and log\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[55], line 146\u001b[0m, in \u001b[0;36mFederatedClient.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[0;32m    140\u001b[0m     lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mLEARNING_RATE,\n\u001b[0;32m    141\u001b[0m     momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mMOMENTUM,\n\u001b[0;32m    142\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mWEIGHT_DECAY,\n\u001b[0;32m    143\u001b[0m )\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mLOCAL_EPOCHS):\n\u001b[1;32m--> 146\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nick\\Documents\\GitHub\\AdvanceML_project5\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:479\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpersistent_workers \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 479\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\u001b[38;5;241m.\u001b[39m_reset(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nick\\Documents\\GitHub\\AdvanceML_project5\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:415\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nick\\Documents\\GitHub\\AdvanceML_project5\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1138\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1131\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1138\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.12.8\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.12.8\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.12.8\\Lib\\multiprocessing\\context.py:337\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.12.8\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.12.8\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fed_model = LeNet(config)\n",
    "fed_trainer = FederatedManager(\n",
    "    model=fed_model,\n",
    "    train_dataset=data.train_dataset,\n",
    "    test_loader=data.test_loader,\n",
    "    config=fed_config,\n",
    ")\n",
    "fed_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_iid_config: FederatedConfig = dataclasses.replace(\n",
    "    fed_config,\n",
    "    CLASSES_PER_CLIENT=5,\n",
    ")\n",
    "\n",
    "# Train with non-iid distribution\n",
    "non_iid_model = LeNet(config)\n",
    "non_iid_trainer = FederatedManager(\n",
    "    model=non_iid_model,\n",
    "    train_dataset=data.train_loader.dataset,\n",
    "    test_loader=data.test_loader,\n",
    "    config=non_iid_config,\n",
    ")\n",
    "non_iid_trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_config = dataclasses.replace(\n",
    "    fed_config, PARTICIPATION_MODE=\"skewed\", DIRICHLET_ALPHA=0.5\n",
    ")\n",
    "\n",
    "skewed_model = LeNet(config)\n",
    "skewed_trainer = FederatedManager(\n",
    "    model=skewed_model,\n",
    "    train_dataset=data.train_loader.dataset,\n",
    "    test_loader=data.test_loader,\n",
    "    config=skewed_config,\n",
    ")\n",
    "skewed_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_epochs_configs: list[FederatedConfig] = [\n",
    "    dataclasses.replace(fed_config, LOCAL_EPOCHS=e) for e in [4, 8, 16]\n",
    "]\n",
    "\n",
    "# Experiment with different client counts\n",
    "client_counts_configs = [\n",
    "    dataclasses.replace(fed_config, NUM_CLIENTS=c) for c in [50, 100, 200]\n",
    "]\n",
    "\n",
    "# Experiment with different participation rates\n",
    "participation_rates_configs = [\n",
    "    dataclasses.replace(fed_config, PARTICIPATION_RATE=r) for r in [0.05, 0.1, 0.2]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Combine all configurations\n",
    "\n",
    "# Get all combinations of parameters\n",
    "all_configs = list(\n",
    "    itertools.product(\n",
    "        [4, 8, 16],  # LOCAL_EPOCHS\n",
    "        [50, 100, 200],  # NUM_CLIENTS\n",
    "        [0.05, 0.1, 0.2],  # PARTICIPATION_RATE\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create FederatedConfig objects for each combination\n",
    "all_experiment_configs = [\n",
    "    dataclasses.replace(\n",
    "        fed_config, LOCAL_EPOCHS=epochs, NUM_CLIENTS=clients, PARTICIPATION_RATE=rate\n",
    "    )\n",
    "    for epochs, clients, rate in all_configs\n",
    "]\n",
    "print(len(all_experiment_configs))\n",
    "# Print all combinations\n",
    "for i, config in enumerate(all_experiment_configs):\n",
    "    print(\n",
    "        i,\n",
    "        f\"LOCAL_EPOCHS={config.LOCAL_EPOCHS}, \"\n",
    "        f\"NUM_CLIENTS={config.NUM_CLIENTS}, \"\n",
    "        f\"PARTICIPATION_RATE={config.PARTICIPATION_RATE}\",\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
